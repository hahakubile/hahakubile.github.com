<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[hahakubile Blog]]></title>
  <link href="http://hahakubile.github.io/atom.xml" rel="self"/>
  <link href="http://hahakubile.github.io/"/>
  <updated>2014-02-24T01:12:40-05:00</updated>
  <id>http://hahakubile.github.io/</id>
  <author>
    <name><![CDATA[hahakubile]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Ubuntu Config Locale With zh_CN.UTF-8]]></title>
    <link href="http://hahakubile.github.io/blog/2014/02/24/ubuntu-config-locale-with-zh-cn-dot-utf-8/"/>
    <updated>2014-02-24T01:06:04-05:00</updated>
    <id>http://hahakubile.github.io/blog/2014/02/24/ubuntu-config-locale-with-zh-cn-dot-utf-8</id>
    <content type="html"><![CDATA[<h3>查看系统内安装的locale</h3>

<p><code>locale -a</code></p>

<h3>查看当前系统语言环境</h3>

<p><code>locale</code></p>

<h3>安装语言包: zh_CN.utf8</h3>

<p><code>cd /usr/share/locales</code>
<code>./install-language-pack zh_CN</code></p>

<h3>设为默认</h3>

<p><code>sudo vim /etc/default/locale</code></p>

<p>修改为:</p>

<p><code>LANG="zh_CN.UTF-8"</code>
<code>LANGUAGE="zh_CN:zh"</code></p>

<h3>重启shell，OK</h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HBase Region Pre-Splitting]]></title>
    <link href="http://hahakubile.github.io/blog/2014/02/20/hbase-region-pre-splitting/"/>
    <updated>2014-02-20T02:52:37-05:00</updated>
    <id>http://hahakubile.github.io/blog/2014/02/20/hbase-region-pre-splitting</id>
    <content type="html"><![CDATA[<h3>Background</h3>

<p>Hbase Version: 0.90.6</p>

<h3>RegionSplitter</h3>

<h4>Usage</h4>

<p>The <code>org.apache.hadoop.hbase.util.RegionSplitter</code> class provides several utilities to create a table with a specified number of pre-split regions.</p>

<p>create a table named &lsquo;myTable&rsquo; with 60 pre-split regions containing 2 column families &lsquo;test&rsquo; &amp; &lsquo;rs&rsquo;</p>

<p><code>bin/hbase org.apache.hadoop.hbase.util.RegionSplitter -c 60 -f test:rs myTable</code></p>

<ul>
<li>-c 60, specifies the requested number of regions as 60</li>
<li>-f specifies the column families you want in the table, separated by &ldquo;:&rdquo;</li>
</ul>


<h4>SplitAlgorithm</h4>

<p><code>MD5StringSplit</code> is the default RegionSplitter.SplitAlgorithm for creating pre-split tables. The format of MD5StringSplit is the ASCII representation of an MD5 checksum. Row are long values in the range &ldquo;00000000&rdquo; => &ldquo;7FFFFFFF&rdquo; and are left-padded with zeros to keep the same order lexographically as if they were binary.</p>

<pre><code>
public static class MD5StringSplit implements SplitAlgorithm {
    final static String MAXMD5 = "7FFFFFFF";
    final static BigInteger MAXMD5_INT = new BigInteger(MAXMD5, 16);

    public byte[][] split(int n) {
        BigInteger[] splits = new BigInteger[n - 1];
        BigInteger sizeOfEachSplit = MAXMD5_INT.divide(BigInteger.valueOf(n));
        for (int i = 1; i < n; i++) {
            // NOTE: this means the last region gets all the slop.
            // This is not a big deal if we're assuming n << MAXMD5
            splits[i - 1] = sizeOfEachSplit.multiply(BigInteger.valueOf(i));
        }
        return convertToBytes(splits);
    }

    ...

}
</code></pre>


<h4>Rowkey Design</h4>

<pre><code>
    String id = "your_id";

    String md5 = org.apache.commons.codec.digest.DigestUtils.md5Hex(id);
    BigInteger x1 = new BigInteger(md5, 16);
    BigInteger x2 = new BigInteger("7FFFFFFF", 16);
    BigInteger x3 = x1.and(x2);
                      
    String rowkey_hash = x3.toString(16);
    while(rowkey_hash.length() < 8){
        rowkey_hash = "0" + rowkey_hash;
    }

    String rowkey = rowkey_hash + "_" + id;
    System.out.println(rowkey);
</code></pre>


<h3>Scenario</h3>

<ul>
<li>Data Size: 4TB</li>
<li>HBase Cluster: 10 nodes</li>
<li>hbase.hregion.max.filesize: 2GB</li>
<li>Cluster Region Count: 4TB/2GB = 2048</li>
<li>Node Region Count: 2048/10 ~= 200</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Compile Sqoop With Specified Hadoop Version]]></title>
    <link href="http://hahakubile.github.io/blog/2014/02/17/how-to-compile-sqoop-with-specified-hadoop-version/"/>
    <updated>2014-02-17T01:11:17-05:00</updated>
    <id>http://hahakubile.github.io/blog/2014/02/17/how-to-compile-sqoop-with-specified-hadoop-version</id>
    <content type="html"><![CDATA[<h2>command</h2>

<ul>
<li>To compile Sqoop, run <code>ant package</code>. There will be a fully self-hosted build provided in the <code>build/sqoop-(version)/</code> directory.</li>
<li>You can build just the jar by running <code>ant jar</code>.</li>
<li>You can specify the <code>hadoopversion</code>, <code>ant -Dhadoopversion=20 package</code></li>
</ul>


<h2>hadoopversion</h2>

<p><a href="https://github.com/apache/sqoop/blob/trunk/build.xml">hadoopversion</a>. Can only be 20, 23, 100, 200 or 210</p>

<h3>20</h3>

<pre><code>
arg1="${hadoopversion}" arg2="20"
name="hadoop.version" value="0.20.2-cdh3u1"
name="hbase94.version" value="0.90.3-cdh3u1"
name="zookeeper.version" value="3.3.3-cdh3u1"
</code></pre>


<h3>23</h3>

<pre><code>
arg1="${hadoopversion}" arg2="23"
name="hadoop.version" value="0.23.1"
name="hbase94.version" value="0.92.0"
name="zookeeper.version" value="3.4.2"
</code></pre>


<h3>100</h3>

<pre><code>
arg1="${hadoopversion}" arg2="100"
name="hadoop.version" value="1.0.0"
name="hbase94.version" value="0.92.0"
name="zookeeper.version" value="3.4.2"
</code></pre>


<h3>200</h3>

<pre><code>
name="hadoop.version" value="2.0.4-alpha"
name="hbase94.version" value="0.94.2"
name="zookeeper.version" value="3.4.2"
</code></pre>


<h3>210</h3>

<pre><code>
name="hadoop.version" value="2.1.0-beta"
name="hbase94.version" value="0.94.2"
name="zookeeper.version" value="3.4.2"
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bulk Load Huge Data From Mysql to HBase Using Sqoop]]></title>
    <link href="http://hahakubile.github.io/blog/2014/02/13/bulk-load-huge-data-from-mysql-to-hbase-using-sqoop/"/>
    <updated>2014-02-13T21:44:36-05:00</updated>
    <id>http://hahakubile.github.io/blog/2014/02/13/bulk-load-huge-data-from-mysql-to-hbase-using-sqoop</id>
    <content type="html"><![CDATA[<h2>MySQL->HBase:HBaseImportJob</h2>

<h2>MySQL->HBase:HBaseBulkImportJob</h2>

<h2>MySQL->HDFS(Avro files)&ndash;>HBase</h2>

<p>Sqoop from MySQL into Avro files in HDFS, this will result in a bunch of avro files in your target directory. You can check that
they&rsquo;re there with <code>hadoop fs -ls $TARGET_DIR</code>.</p>

<p><code>sqoop import --connect jdbc:mysql://$MYSQL_SERVER/$DATABASE --driver com.mysql.jdbc.Driver --username $USER --password $PASSWORD --table $TABLE --target-dir $TARGET_DIR --as-avrodatafile</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Configuring Ulimit for HBase in Cloudera Cdh3u6]]></title>
    <link href="http://hahakubile.github.io/blog/2014/02/13/configuring-ulimit-for-hbase-in-cloudera-cdh3u6/"/>
    <updated>2014-02-13T02:57:04-05:00</updated>
    <id>http://hahakubile.github.io/blog/2014/02/13/configuring-ulimit-for-hbase-in-cloudera-cdh3u6</id>
    <content type="html"><![CDATA[<h2>Error in hbase regionserver log</h2>

<pre><code>2014-02-13 11:38:13,028 INFO org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.101.21:50010, add to deadNodes and continue
java.net.SocketException: Too many open files
</code></pre>

<h2>About ulimit</h2>

<p><a href="http://hbase.apache.org/book.html#ulimit">http://hbase.apache.org/book.html#ulimit</a></p>

<p>To be clear, upping the file descriptors and nproc for the user who is running the HBase process is an operating system configuration, not an HBase configuration.</p>

<h2><a href="http://essayboard.com/2011/05/28/raising-ulimit-on-centos-server/">Raising ulimit on centos-server</a></h2>

<h3>fs.file-max</h3>

<ol>
<li><code>vim /etc/sysctl.conf</code></li>
<li>Add this line <code>fs.file-max = 122880</code> into <code>/etc/sysctl.conf</code></li>
<li>You can execute the command <code>sysctl -p</code> or reboot to permanently add the kernel parameter above

<h3>ulimit</h3></li>
<li><code>vim /etc/security/limits.conf</code></li>
<li>Add the lines below:

<ul>
<li>soft nofile 122880</li>
<li>hard nofile 122880</li>
</ul>
</li>
<li>logout and login, execute the command <code>ulimit -n</code> inside your terminal.
If you had done everything correctly, you should now see a value returns as 122880.</li>
</ol>


<h2>CM users</h2>

<p>For CM users, since there&rsquo;s a supervisor in effect that monitors the launched daemons, the ulimits are inherited from it and are hence pre-set in <code>/usr/sbin/cmf-agent</code> (look for lines that start with &ldquo;ulimit&rdquo;.</p>

<ol>
<li>Edit /usr/sbin/cmf-agent and change the ulimit -n setting.</li>
<li>shutdown hdfs/mapreduce/hbase services on them.</li>
<li>On these stopped nodes run: <code>service cloudera-scm-agent hard_restart</code></li>
<li>Restart the services.</li>
</ol>


<h2>How to confirm</h2>

<p>To confirm, you can go to any CM-managed node, <code>ps -ef | grep hdfs</code>, grab the pid of a hdfs process.
<code>cat /proc/&lt;pid&gt;/fd</code> to make sure it&rsquo;s sticking.</p>

<pre><code>Limit                     Soft Limit           Hard Limit           Units     
Max processes             65536                65536                processes 
Max open files            122880               122880               files 
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Centos 5.8: python2.7.5 + scrapy0.16.4 Install]]></title>
    <link href="http://hahakubile.github.io/blog/2014/02/06/centos-5-dot-8-python2-dot-7-5-plus-scrapy0-dot-16-dot-4-install/"/>
    <updated>2014-02-06T21:42:00-05:00</updated>
    <id>http://hahakubile.github.io/blog/2014/02/06/centos-5-dot-8-python2-dot-7-5-plus-scrapy0-dot-16-dot-4-install</id>
    <content type="html"><![CDATA[<h2>1. System support</h2>

<p>Before you install python 2.7 in centos 5.*, first check https/zlib/bzip2 support</p>

<ul>
<li>Compression requires the (missing) zlib module<br/>
  <code>yum -y install zlib zlib-devel</code></li>
<li>unknown url type: https &mdash; Some packages may not be found!
  <code>yum -y install openssl openssl-devel</code></li>
<li>python -c &ldquo;import bz2; print bz2.<strong>doc</strong>&rdquo; ==> CompressionError: bz2 module is not available
  <code>yum -y install bzip2 bzip2-devel</code></li>
</ul>


<h2>2. Install Python 2.7.5</h2>

<p>When you are with CentOS 5.*, you will see that Python is at version 2.4.3, it is reserved for system&rsquo;s use.
Next we are going to install Python 2.7.5 without breaking the system&rsquo;s default.
It is rather important to not to get involved with that as critical system tools such as YUM depend on it.</p>

<h3>2.1 download &amp; install</h3>

<pre><code>
wget http://www.python.org/ftp/python/2.7.5/Python-2.7.5.tgz -P /opt
cd /opt
tar xvf Python-2.7.5.tgz
cd Python-2.7.5
./configure --prefix=/usr/local
# make altinstall is used to prevent replacing the default python binary file /usr/bin/python
make && make altinstall
</pre>


<p></code></p>

<h3>2.2 Adding New Python Installation Location to $PATH</h3>

<p><code>export PATH="/usr/local/bin:$PATH"</code><br/>
or you can(recommended):
<code>echo "export PATH=\"/usr/local/bin:\$PATH\"" &gt;&gt; /etc/profile &amp;&amp; source /etc/profile</code></p>

<h3>2.3 check python command</h3>

<p><code>python2.7 -c "import sys; print sys.version"</code></p>

<h3>2.4 install setuptools</h3>

<pre><code>
wget --no-check-certificate https://pypi.python.org/packages/source/s/setuptools/setuptools-1.4.2.tar.gz -P /opt
tar xvf setuptools-1.4.2.tar.gz
cd setuptools-1.4.2
# Be careful, python2.7 here
python2.7 setup.py install
</pre>


<p></code></p>

<h3>2.5 install pip</h3>

<p><code>curl https://raw.github.com/pypa/pip/master/contrib/get-pip.py | python2.7 -</code></p>

<h2>3. <a href="http://doc.scrapy.org/en/latest/intro/install.html">Scrapy install</a></h2>

<h3>3.1 Pre-requisites</h3>

<ul>
<li>Python 2.7</li>
<li>lxml</li>
<li>pip or easy_install</li>
</ul>


<h3>3.2 lxml</h3>

<p>@see <a href="http://lxml.de/installation.html">http://lxml.de/installation.html</a></p>

<p><code>yum -y install libxml2 libxml2-devel libxslt libxslt-devel</code></p>

<h3>3.3 scrapy</h3>

<p>@see <a href="http://stackoverflow.com/questions/7340784/easy-install-pyopenssl-error">http://stackoverflow.com/questions/7340784/easy-install-pyopenssl-error</a>
<code>pip install pyOpenSSL==0.12</code></p>

<p><code>pip install Scrapy==0.16.4</code></p>

<h2>4. Optional: Redis/Hiredis/MySQL-Python/SQLAlchemy/PIL/DBUtils</h2>

<pre><code>
pip install redis hiredis

yum install mysql-devel
pip install MySQL-python

pip install SQLAlchemy

yum install libjpeg libjpeg-devel freetype freetype-devel libpng libpng-devel
pip install http://effbot.org/media/downloads/Imaging-1.1.7.tar.gz

pip install DBUtils

</pre>


<p></code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction-Optimizing Search Engines Using Clickthrough Data]]></title>
    <link href="http://hahakubile.github.io/blog/2012/07/04/introduction-optimizing-search-engines-using-clickthrough-data/"/>
    <updated>2012-07-04T10:59:00-04:00</updated>
    <id>http://hahakubile.github.io/blog/2012/07/04/introduction-optimizing-search-engines-using-clickthrough-data</id>
    <content type="html"><![CDATA[<h3>基本</h3>

<ul>
<li>Relevant docs high, less relevant docs below</li>
<li>training dat</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Problem-printf Std String]]></title>
    <link href="http://hahakubile.github.io/blog/2012/06/29/problem-printf-std-string/"/>
    <updated>2012-06-29T11:14:00-04:00</updated>
    <id>http://hahakubile.github.io/blog/2012/06/29/problem-printf-std-string</id>
    <content type="html"><![CDATA[<h3>问题</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="cp">#include &lt;stdio.h&gt;</span>
</span><span class='line'><span class="cp">#include &lt;string&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="kt">int</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>   <span class="n">string</span> <span class="n">a</span> <span class="o">=</span> <span class="s">&quot;test&quot;</span><span class="p">;</span>
</span><span class='line'>   <span class="n">printf</span><span class="p">(</span><span class="s">&quot;%s/n&quot;</span><span class="p">,</span> <span class="n">a</span><span class="p">);</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>编译错误</h3>

<ul>
<li> warning: cannot pass objects of non-POD type ‘struct std::string’ through ‘&hellip;’; callcall will abort at runtime</li>
<li> warning: format ‘%s’ expects type ‘char*’, but argument 2 has type ‘int’</li>
</ul>


<h3>原因</h3>

<ul>
<li> printf只能输出C语言内置的数据，而string不是内置的，只是一个扩展的类</li>
<li> &amp;a代表的是这个字符串的存储地址，并不是指向字符串的首地址</li>
</ul>


<h3>解决</h3>

<pre><code>printf("%s\n", a.c_str());
</code></pre>

<ul>
<li>const char *c_str();</li>
<li>c_str()提供了这样一种方法，它返回const char*类型(可读不可改)的指向字符数组的指针</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[About Static_cast]]></title>
    <link href="http://hahakubile.github.io/blog/2012/06/25/about-static-cast/"/>
    <updated>2012-06-25T14:06:00-04:00</updated>
    <id>http://hahakubile.github.io/blog/2012/06/25/about-static-cast</id>
    <content type="html"><![CDATA[<h3>static_cast</h3>

<pre><code>static_cast&lt;type&gt; (object);
</code></pre>

<p>The static_cast operator can be used for operations such as:</p>

<ul>
<li>Converting a pointer of a base class to a pointer of a derived class,</li>
<li>Convert numeric data types such as enums to ints or ints to floats.</li>
</ul>


<h3>示例</h3>

<pre><code>int score = 1340;

float scale = static_cast&lt;float&gt;(score) / MAX_SCORE + 1;

// 如果这样呢？会有什么不同
float scale = score / MAX_SCORE + 1;
</code></pre>

<p>需要注意的是，在基础类型转换时，并非进行四舍五入，而是直接舍去小数部分！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Avoid Assigning Negative Numbers to Unsigned Int|short]]></title>
    <link href="http://hahakubile.github.io/blog/2012/06/25/avoid-assigning-negative-numbers-to-unsigned-short/"/>
    <updated>2012-06-25T11:57:00-04:00</updated>
    <id>http://hahakubile.github.io/blog/2012/06/25/avoid-assigning-negative-numbers-to-unsigned-short</id>
    <content type="html"><![CDATA[<h3>问题</h3>

<pre><code>// 定义了一个int变量i，i存在为负数的情况
int i = -1; 
// 又定义了一个unsigned short or int的变量j
unsigned short j;
// 如果把i的值赋给j
j = i; 

// 会发生什么？j为65535
std::cout &lt;&lt; j &lt;&lt; std::endl;
</code></pre>

<h3>结论</h3>

<p>这是一个简单的赋值，但由于前后未注意，导致这种bug发生，试想如果后面使用下面语句进行判断的话：</p>

<pre><code>if(j &gt; 0) {
  // 这里，j本应该是-1，但由于65535&gt;0，导致错误
}
</code></pre>

<p>看到一句很有意思的话，You&rsquo;re lying to the compiler.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Select All Columns Except Some in MySQL]]></title>
    <link href="http://hahakubile.github.io/blog/2012/06/16/select-all-columns-except-some-in-mysql/"/>
    <updated>2012-06-16T13:58:00-04:00</updated>
    <id>http://hahakubile.github.io/blog/2012/06/16/select-all-columns-except-some-in-mysql</id>
    <content type="html"><![CDATA[<h3>问题</h3>

<p>如果一个表有多列，要想不查询指定列（其余列都要），该如何实现？</p>

<p>在stackoverflow上有类似的问题，<a href="http://stackoverflow.com/questions/9122/select-all-columns-except-one-in-mysql/11060861#11060861">Select all columns except one in MySQL?</a></p>

<h3>实现</h3>

<pre><code>SET @database    = 'database_name';
SET @tablename   = 'table_name';
SET @cols2delete = 'col1,col2,col3';

#If you do have a lots of cols, use this sql to change group_concat_max_len
SET @@group_concat_max_len = 2048;  

SET @sql = CONCAT(
'SELECT ', 
(
    SELECT GROUP_CONCAT( IF(FIND_IN_SET(COLUMN_NAME, @cols2delete), NULL, COLUMN_NAME ) )
    FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = @tablename AND TABLE_SCHEMA = @database
), 
' FROM ',
@tablename);

SELECT @sql;

PREPARE stmt1 FROM @sql;
EXECUTE stmt1;
</code></pre>

<h3>说明</h3>

<p>涉及到以下内容：</p>

<ul>
<li>从INFORMATION_SCHEMA.COLUMNS表中获取COLUMNS名称</li>
<li>GROUP_CONCAT拼接在一起</li>
<li>FIND_IN_SET判断是否在排除的列当中</li>
<li>IF语句使用</li>
<li>Mysql prepare&hellip;execute用法</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Problem-Running Weka-Registering Weka Editors Error]]></title>
    <link href="http://hahakubile.github.io/blog/2012/06/12/problem-running-weka-registering-weka-editors-error/"/>
    <updated>2012-06-12T14:10:00-04:00</updated>
    <id>http://hahakubile.github.io/blog/2012/06/12/problem-running-weka-registering-weka-editors-error</id>
    <content type="html"><![CDATA[<h3>ubuntu下安装weka</h3>

<pre><code>sudo apt-get install weka
</code></pre>

<h3>启动weka，控制台打印warning如下：</h3>

<pre><code>---Registering Weka Editors---
Trying to add JDBC driver: RmiJdbc.RJDriver - Error, not in CLASSPATH?
Trying to add JDBC driver: jdbc.idbDriver - Error, not in CLASSPATH?
Trying to add JDBC driver: org.gjt.mm.mysql.Driver - Error, not in CLASSPATH?
Trying to add JDBC driver: com.mckoi.JDBCDriver - Error, not in CLASSPATH?
Trying to add JDBC driver: org.hsqldb.jdbcDriver - Error, not in CLASSPATH?
</code></pre>

<h3>问题原因</h3>

<blockquote><p>These are actually just warnings rather than true errors.
The system has some default connection strings for various common databases and
Weka does a quick check to see if the appropriate JDBC drivers are available to the system at startup.
If you are not planning to connect to MySQL, Hypersonic, instantdb etc. then these messages can safely be ignored.</p></blockquote>

<p>也就是说，这是weka的例行检查，如果不打算连接数据库，完全可以忽略这些warning信息。</p>

<h3>解决办法</h3>

<ul>
<li>下载对应的jar包（上面这些都是用于连接不同数据库）</li>
<li>修改/usr/bin/weka启动脚本，添加JAVA_CLASSPTH（也可添加在~/.bashrc中）</li>
</ul>


<h3>参考[1]、[2]、[3]</h3>

<p><a href="http://www.cnblogs.com/luffylee/archive/2012/02/23/2365416.html">1</a>
<a href="http://www.blogjava.net/honeybee/articles/193605.html">2</a>
<a href="http://forums.pentaho.com/showthread.php?82144-quot-Trying-to-add-database-driver-quot-issue">3</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Problem-SSH Permissions Denied: This Private Key Are Too Open]]></title>
    <link href="http://hahakubile.github.io/blog/2012/06/11/problem-ssh-permissions-denied-this-private-key-are-too-open/"/>
    <updated>2012-06-11T10:32:00-04:00</updated>
    <id>http://hahakubile.github.io/blog/2012/06/11/problem-ssh-permissions-denied-this-private-key-are-too-open</id>
    <content type="html"><![CDATA[<h3>问题:</h3>

<pre><code>$ ssh -T git@github.com     
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@         WARNING: UNPROTECTED PRIVATE KEY FILE!          @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Permissions 0766 for '***/.ssh/id_rsa' are too open.
It is recommended that your private key files are NOT accessible by others.
This private key will be ignored.
bad permissions: ignore key: ***/.ssh/id_rsa
Permission denied (publickey).
</code></pre>

<h3>解决方法:</h3>

<pre><code>cd ~/.ssh
chmod 700 id_rsa
</code></pre>

<h3>参考：<a href="http://stackoverflow.com/questions/1556119/ssh-private-key-permissions-using-git-gui-or-ssh-keygen-are-too-open">1</a>、<a href="http://www.thinkplexx.com/learn/howto/security/ssh/fix-permissions-are-too-open-private-key-will-be-ignored">2</a></h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[About IronSpread]]></title>
    <link href="http://hahakubile.github.io/blog/2012/06/11/about-ironspread/"/>
    <updated>2012-06-11T10:04:00-04:00</updated>
    <id>http://hahakubile.github.io/blog/2012/06/11/about-ironspread</id>
    <content type="html"><![CDATA[<h3>IronSpread: Scripting Excel with Python</h3>

<ul>
<li>MIT的两名学生开发的Excel 2010 插件</li>
<li>替代VBA</li>
<li>允许用户在Excel中创建自动化的任务</li>
</ul>


<p>相比之前使用python的插件完成excel清理，也许这会是个方便的选择。</p>

<p><a href="http://www.ironspread.com/quickstart.html">@QucikStart</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[学而时习之，不亦乐乎]]></title>
    <link href="http://hahakubile.github.io/blog/2012/06/08/xue-er-shi-xi-zhi-%2Cbu-yi-le-hu/"/>
    <updated>2012-06-08T21:05:00-04:00</updated>
    <id>http://hahakubile.github.io/blog/2012/06/08/xue-er-shi-xi-zhi-,bu-yi-le-hu</id>
    <content type="html"><![CDATA[<ul>
<li><p>温故而知新</p></li>
<li><p>学而时习之</p></li>
<li><p>有朋自远方来</p></li>
<li><p>会当凌绝顶</p></li>
</ul>

]]></content>
  </entry>
  
</feed>
